{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm, os\n",
    "import json, requests, torch\n",
    "from multiprocessing import Pool\n",
    "import json, pandas as pd, numpy as np, os\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_dynamics(model_dir: os.path,\n",
    "                           strip_last: bool = False,\n",
    "                           id_field: str = \"guid\",\n",
    "                           burn_out: int = None):\n",
    "  \"\"\"\n",
    "  Given path to logged training dynamics, merge stats across epochs.\n",
    "  Returns:\n",
    "  - Dict between ID of a train instances and its gold label, and the list of logits across epochs.\n",
    "  \"\"\"\n",
    "  train_dynamics = {}\n",
    "\n",
    "  td_dir = os.path.join(model_dir, \"training_dynamics\")\n",
    "  num_epochs = len([f for f in os.listdir(td_dir) if os.path.isfile(os.path.join(td_dir, f))])\n",
    "  if burn_out:\n",
    "    num_epochs = burn_out\n",
    "\n",
    "  print(f\"Reading {num_epochs} files from {td_dir} ...\")\n",
    "  for epoch_num in tqdm.tqdm(range(num_epochs)):\n",
    "    epoch_file = os.path.join(td_dir, f\"dynamics_epoch_{epoch_num}.jsonl\")\n",
    "    assert os.path.exists(epoch_file)\n",
    "\n",
    "    with open(epoch_file, \"r\") as infile:\n",
    "      for line in infile:\n",
    "        record = json.loads(line.strip())\n",
    "        guid = record[id_field] if not strip_last else record[id_field][:-1]\n",
    "        if guid not in train_dynamics:\n",
    "          assert epoch_num == 0\n",
    "          train_dynamics[guid] = {\"gold\": record[\"gold\"], \"logits\": []}\n",
    "        train_dynamics[guid][\"logits\"].append(record[f\"logits_epoch_{epoch_num}\"])\n",
    "\n",
    "  print(f\"Read training dynamics for {len(train_dynamics)} train instances.\")\n",
    "  return train_dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import List\n",
    "\n",
    "def compute_forgetfulness(correctness_trend: List[float]) -> int:\n",
    "  \"\"\"\n",
    "  Given a epoch-wise trend of train predictions, compute frequency with which\n",
    "  an example is forgotten, i.e. predicted incorrectly _after_ being predicted correctly.\n",
    "  Based on: https://arxiv.org/abs/1812.05159\n",
    "  \"\"\"\n",
    "  if not any(correctness_trend):  # Example is never predicted correctly, or learnt!\n",
    "      return 1000\n",
    "  learnt = False  # Predicted correctly in the current epoch.\n",
    "  times_forgotten = 0\n",
    "  for is_correct in correctness_trend:\n",
    "    if (not learnt and not is_correct) or (learnt and is_correct):\n",
    "      # nothing changed.\n",
    "      continue\n",
    "    elif learnt and not is_correct:\n",
    "      # Forgot after learning at some point!\n",
    "      learnt = False\n",
    "      times_forgotten += 1\n",
    "    elif not learnt and is_correct:\n",
    "      # Learnt!\n",
    "      learnt = True\n",
    "  return times_forgotten\n",
    "\n",
    "\n",
    "def compute_correctness(trend: List[float]) -> float:\n",
    "  \"\"\"\n",
    "  Aggregate #times an example is predicted correctly during all training epochs.\n",
    "  \"\"\"\n",
    "  return sum(trend)\n",
    "\n",
    "\n",
    "\n",
    "def compute_train_dy_metrics(training_dynamics):\n",
    "  \"\"\"\n",
    "  Given the training dynamics (logits for each training instance across epochs), compute metrics\n",
    "  based on it, for data map coorodinates.\n",
    "  Computed metrics are: confidence, variability, correctness, forgetfulness, threshold_closeness---\n",
    "  the last two being baselines from prior work\n",
    "  (Example Forgetting: https://arxiv.org/abs/1812.05159 and\n",
    "   Active Bias: https://arxiv.org/abs/1704.07433 respectively).\n",
    "  Returns:\n",
    "  - DataFrame with these metrics.\n",
    "  - DataFrame with more typical training evaluation metrics, such as accuracy / loss.\n",
    "  \"\"\"\n",
    "  confidence_ = {}\n",
    "  variability_ = {}\n",
    "  threshold_closeness_ = {}\n",
    "  correctness_ = {}\n",
    "  forgetfulness_ = {}\n",
    "\n",
    "  # Functions to be applied to the data.\n",
    "  variability_func = lambda conf: np.std(conf)\n",
    "  threshold_closeness_func = lambda conf: conf * (1 - conf)\n",
    "\n",
    "  loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "  num_tot_epochs = len(list(training_dynamics.values())[0][\"logits\"])\n",
    "  print(f\"Computing training dynamics across {num_tot_epochs} epochs\")\n",
    "  print(\"Metrics computed: confidence, variability, correctness, forgetfulness, threshold_closeness\")\n",
    "\n",
    "  logits = {i: [] for i in range(num_tot_epochs)}\n",
    "  targets = {i: [] for i in range(num_tot_epochs)}\n",
    "  training_accuracy = defaultdict(float)\n",
    "\n",
    "  for guid in tqdm.tqdm(training_dynamics):\n",
    "    correctness_trend = []\n",
    "    true_probs_trend = []\n",
    "\n",
    "    record = training_dynamics[guid]\n",
    "    for i, epoch_logits in enumerate(record[\"logits\"]):\n",
    "      probs = torch.nn.functional.softmax(torch.Tensor(epoch_logits), dim=-1)\n",
    "      true_class_prob = float(probs[record[\"gold\"]])\n",
    "      true_probs_trend.append(true_class_prob)\n",
    "\n",
    "      prediction = np.argmax(epoch_logits)\n",
    "      is_correct = (prediction == record[\"gold\"]).item()\n",
    "      correctness_trend.append(is_correct)\n",
    "\n",
    "      training_accuracy[i] += is_correct\n",
    "      logits[i].append(epoch_logits)\n",
    "      targets[i].append(record[\"gold\"])\n",
    "\n",
    "    # if burn_out < num_tot_epochs:\n",
    "    #   correctness_trend = correctness_trend[:args.burn_out]\n",
    "    #   true_probs_trend = true_probs_trend[:args.burn_out]\n",
    "\n",
    "    correctness_[guid] = compute_correctness(correctness_trend)\n",
    "    confidence_[guid] = np.mean(true_probs_trend)\n",
    "    variability_[guid] = variability_func(true_probs_trend)\n",
    "\n",
    "    forgetfulness_[guid] = compute_forgetfulness(correctness_trend)\n",
    "    threshold_closeness_[guid] = threshold_closeness_func(confidence_[guid])\n",
    "\n",
    "  # Should not affect ranking, so ignoring.\n",
    "  epsilon_var = np.mean(list(variability_.values()))\n",
    "\n",
    "  column_names = ['guid',\n",
    "                  'index',\n",
    "                  'threshold_closeness',\n",
    "                  'confidence',\n",
    "                  'variability',\n",
    "                  'correctness',\n",
    "                  'forgetfulness',]\n",
    "  df = pd.DataFrame([[guid,\n",
    "                      i,\n",
    "                      threshold_closeness_[guid],\n",
    "                      confidence_[guid],\n",
    "                      variability_[guid],\n",
    "                      correctness_[guid],\n",
    "                      forgetfulness_[guid],\n",
    "                      ] for i, guid in enumerate(correctness_)], columns=column_names)\n",
    "\n",
    "  df_train = pd.DataFrame([[i,\n",
    "                            loss(torch.Tensor(logits[i]), torch.LongTensor(targets[i])).item() / len(training_dynamics),\n",
    "                            training_accuracy[i] / len(training_dynamics)\n",
    "                            ] for i in range(num_tot_epochs)],\n",
    "                          columns=['epoch', 'loss', 'train_acc'])\n",
    "  return df, df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 6 files from ../cartography/outputs/training_dynamics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read training dynamics for 25000 train instances.\n",
      "Computing training dynamics across 6 epochs\n",
      "Metrics computed: confidence, variability, correctness, forgetfulness, threshold_closeness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:04<00:00, 5939.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# model_dir = \"/home/pritam.k/research/hf_audit/cart/financial_phrasebank/real_model/saved_tds/\": \n",
    "model_dir = \"../cartography/outputs\"\n",
    "# model_dir = \"/home/pritam.k/research/hf_audit/cart/amazon_multi_reviews_v1/\"\n",
    "\n",
    "training_dynamics = read_training_dynamics(model_dir,\n",
    "                                            strip_last=False,\n",
    "                                            burn_out=None)\n",
    "df_cart, _ = compute_train_dy_metrics(training_dynamics)\n",
    "df_cart = df_cart.assign(corr_frac = lambda d: d.correctness / d.correctness.max())\n",
    "df_cart['correct'] = [f\"{x:.2f}\" for x in df_cart['corr_frac']]\n",
    "\n",
    "df_cart['correct'] = df_cart['correct'].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>index</th>\n",
       "      <th>threshold_closeness</th>\n",
       "      <th>confidence</th>\n",
       "      <th>variability</th>\n",
       "      <th>correctness</th>\n",
       "      <th>forgetfulness</th>\n",
       "      <th>corr_frac</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101761</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081642</td>\n",
       "      <td>0.910315</td>\n",
       "      <td>0.191507</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124457</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078446</td>\n",
       "      <td>0.914191</td>\n",
       "      <td>0.186969</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107079</td>\n",
       "      <td>2</td>\n",
       "      <td>0.074944</td>\n",
       "      <td>0.918396</td>\n",
       "      <td>0.180779</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102292</td>\n",
       "      <td>3</td>\n",
       "      <td>0.246512</td>\n",
       "      <td>0.559061</td>\n",
       "      <td>0.417149</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120856</td>\n",
       "      <td>4</td>\n",
       "      <td>0.082579</td>\n",
       "      <td>0.909171</td>\n",
       "      <td>0.199691</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     guid  index  threshold_closeness  confidence  variability  correctness  \\\n",
       "0  101761      0             0.081642    0.910315     0.191507            5   \n",
       "1  124457      1             0.078446    0.914191     0.186969            5   \n",
       "2  107079      2             0.074944    0.918396     0.180779            6   \n",
       "3  102292      3             0.246512    0.559061     0.417149            4   \n",
       "4  120856      4             0.082579    0.909171     0.199691            5   \n",
       "\n",
       "   forgetfulness  corr_frac  correct  \n",
       "0              0   0.833333     0.83  \n",
       "1              0   0.833333     0.83  \n",
       "2              0   1.000000     1.00  \n",
       "3              1   0.666667     0.67  \n",
       "4              0   0.833333     0.83  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_cart\n",
    "df[\"difficulty\"] = pd.cut(df[\"correct\"], bins=[-1.0, 0.2, 0.8, 1.0], labels=[\"hard\", \"ambiguous\", \"easy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>index</th>\n",
       "      <th>threshold_closeness</th>\n",
       "      <th>confidence</th>\n",
       "      <th>variability</th>\n",
       "      <th>correctness</th>\n",
       "      <th>forgetfulness</th>\n",
       "      <th>corr_frac</th>\n",
       "      <th>correct</th>\n",
       "      <th>difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101761</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081642</td>\n",
       "      <td>0.910315</td>\n",
       "      <td>0.191507</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.83</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124457</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078446</td>\n",
       "      <td>0.914191</td>\n",
       "      <td>0.186969</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.83</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107079</td>\n",
       "      <td>2</td>\n",
       "      <td>0.074944</td>\n",
       "      <td>0.918396</td>\n",
       "      <td>0.180779</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102292</td>\n",
       "      <td>3</td>\n",
       "      <td>0.246512</td>\n",
       "      <td>0.559061</td>\n",
       "      <td>0.417149</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.67</td>\n",
       "      <td>ambiguous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120856</td>\n",
       "      <td>4</td>\n",
       "      <td>0.082579</td>\n",
       "      <td>0.909171</td>\n",
       "      <td>0.199691</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.83</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     guid  index  threshold_closeness  confidence  variability  correctness  \\\n",
       "0  101761      0             0.081642    0.910315     0.191507            5   \n",
       "1  124457      1             0.078446    0.914191     0.186969            5   \n",
       "2  107079      2             0.074944    0.918396     0.180779            6   \n",
       "3  102292      3             0.246512    0.559061     0.417149            4   \n",
       "4  120856      4             0.082579    0.909171     0.199691            5   \n",
       "\n",
       "   forgetfulness  corr_frac  correct difficulty  \n",
       "0              0   0.833333     0.83       easy  \n",
       "1              0   0.833333     0.83       easy  \n",
       "2              0   1.000000     1.00       easy  \n",
       "3              1   0.666667     0.67  ambiguous  \n",
       "4              0   0.833333     0.83       easy  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "difficulty\n",
       "easy         24278\n",
       "ambiguous      681\n",
       "hard            41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.difficulty.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
