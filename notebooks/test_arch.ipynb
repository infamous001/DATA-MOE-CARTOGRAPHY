{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef602fde-19c7-4fd3-90e4-aaac6771a407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pritam.k/research/envs/hf-envs/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, os, evaluate, sys\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "import dataclasses, sys, pickle, json\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt, random, numpy as np\n",
    "\n",
    "from datasets import load_dataset,Dataset,DatasetDict\n",
    "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW,get_scheduler\n",
    "from datasets import load_metric\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "sys.path.append(\"/home/pritam.k/research/data-moe\")\n",
    "\n",
    "\n",
    "# from src.utils.helper import CustomModel, ModelArgs, MoeArgs\n",
    "from src.utils.helper import ConfiguredMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352be1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pritam.k/research/data-moe/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb94a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=128, padding=True)\n",
    "\n",
    "os.environ[\"HF_HOME\"]=\"/home/pritam.k/research/huggingface\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "checkpoint = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "with open(\"../results/best_hyperparameters_tweet_eval.json\", \"r\") as jfile:\n",
    "    hp_params=json.load(jfile)\n",
    "\n",
    "lr=hp_params['learning_rate']\n",
    "batch_size=hp_params['per_device_train_batch_size']\n",
    "num_epochs=hp_params['num_train_epochs']\n",
    "num_experts=3\n",
    "num_experts_per_tok=1\n",
    "mode=f\"{num_experts}_{num_experts_per_tok}_test\" #ce/cbz/cb/cz/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad64b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example tensor for difficulty levels\n",
    "# # Difficulty mapping: 0 for easy, 1 for ambiguous, 2 for hard\n",
    "# difficulty = torch.tensor([0 if instance in easy_ids else 1 if instance in ambi_ids else 2 for instance in hard_ids], device=device)\n",
    "\n",
    "# # Pass the difficulty levels to the model during forward pass\n",
    "# output, expert_tracking = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask, labels=batch_labels, difficulty_levels=difficulty_levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a798c95-18f3-4f61-aeaf-e6b537f26482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'split', 'idx', 'difficulty'],\n",
      "        num_rows: 45615\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['text', 'label', 'split', 'idx', 'difficulty'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'split', 'idx', 'difficulty'],\n",
      "        num_rows: 12284\n",
      "    })\n",
      "})\n",
      "Dataset({\n",
      "    features: ['labels', 'global_index', 'difficulty', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 45615\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds_train = load_dataset('csv', data_files='../data/tweet_eval/updated/train.csv')\n",
    "ds_val = load_dataset('csv', data_files='../data/tweet_eval/updated/val.csv')\n",
    "ds_test = load_dataset('csv', data_files='../data/tweet_eval/updated/test.csv')\n",
    "\n",
    "#print(ds)\n",
    "#sys.exit()\n",
    "data = DatasetDict({\n",
    "    'train': ds_train['train'],\n",
    "    'valid': ds_val['train'],\n",
    "    'test': ds_test['train']}  \n",
    ")\n",
    "\n",
    "print(data)\n",
    "#sys.exit()\n",
    "tokenized_dataset = data.map(preprocess_function, batched=True, num_proc=12)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\", \"split\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"idx\", \"global_index\")\n",
    "#tokenized_dataset.set_format(\"torch\")\n",
    "tokenized_dataset.set_format(\"torch\",columns=[\"global_index\",\"input_ids\", \"attention_mask\", \"labels\", \"difficulty\"])\n",
    "print(tokenized_dataset[\"train\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"train\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"valid\"], batch_size=batch_size, collate_fn=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2849197b-9c80-4aaf-ada6-560dc666816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_loss(logits):\n",
    "    log_sum_exp=torch.logsumexp(logits,dim=1)\n",
    "    sq_log_sum_exp=log_sum_exp=log_sum_exp**2\n",
    "    loss=torch.mean(sq_log_sum_exp)\n",
    "    return loss\n",
    "\n",
    "def b_loss(logits,alpha=1e-2):\n",
    "    T,N=logits.shape\n",
    "    probs=torch.softmax(logits,dim=1)\n",
    "\n",
    "    argmax_experts=torch.argmax(probs,dim=1)\n",
    "    f=torch.zeros(N,device=logits.device)\n",
    "    for i in range(N):\n",
    "        f[i]=(argmax_experts==i).float().mean()\n",
    "    P=probs.mean(dim=0)\n",
    "\n",
    "    loss=alpha*N*torch.sum(f*P)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dda690e-c980-4f96-8759-986977486eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class MoeArgs:\n",
    "    def __init__(self, num_experts: int,num_experts_per_tok):\n",
    "        self.num_experts=num_experts\n",
    "        self.num_experts_per_tok=num_experts_per_tok\n",
    "\n",
    "# class MoeLayer(nn.Module):\n",
    "#     def __init__(self, experts: List[nn.Module], gate: nn.Module, moe_args: MoeArgs):\n",
    "#         super().__init__()\n",
    "#         assert len(experts) > 0\n",
    "#         self.gate = gate\n",
    "#         self.experts = nn.ModuleList(experts)\n",
    "#         self.args = moe_args\n",
    "#         #self.expert_assignments = None\n",
    "\n",
    "#     def forward(self, inputs: torch.Tensor):\n",
    "#         gate_logits = self.gate(inputs)\n",
    "#         loss_z=z_loss(gate_logits)\n",
    "#         loss_b=b_loss(gate_logits)\n",
    "#         weights,selected_experts = torch.topk(gate_logits, self.args.num_experts_per_tok)\n",
    "#         weights = F.softmax(weights, dim=1, dtype=torch.float).to(inputs.dtype)\n",
    "#         results = torch.zeros_like(inputs)\n",
    "#         expert_tracking = {i: [] for i in range(self.args.num_experts)}\n",
    "#         for current_expert_index, current_expert in enumerate(self.experts):\n",
    "#             token_index, token_expert_index = torch.where(selected_experts == current_expert_index)\n",
    "#             for idx in token_index.cpu().numpy():\n",
    "#                 expert_tracking[current_expert_index].append(idx)\n",
    "#             results[token_index] += weights[token_index, token_expert_index, None] * current_expert(\n",
    "#                 inputs[token_index]\n",
    "#             )\n",
    "#         return results,loss_z,loss_b,expert_tracking\n",
    "\n",
    "\n",
    "class MoeLayer(nn.Module):\n",
    "    def __init__(self, experts: List[nn.Module], gate: nn.Module, moe_args: MoeArgs):\n",
    "        super().__init__()\n",
    "        assert len(experts) > 0\n",
    "        self.gate = gate\n",
    "        self.experts = nn.ModuleList(experts)\n",
    "        self.args = moe_args\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, expert_assignments=None):\n",
    "        gate_logits = self.gate(inputs)\n",
    "        loss_z = z_loss(gate_logits)\n",
    "        loss_b = b_loss(gate_logits)\n",
    "\n",
    "        # If expert_assignments is provided, override the gating mechanism\n",
    "        if expert_assignments is not None:\n",
    "            selected_experts = expert_assignments\n",
    "            weights = torch.ones(inputs.size(0), self.args.num_experts_per_tok, dtype=inputs.dtype, device=inputs.device)\n",
    "        else:\n",
    "            weights, selected_experts = torch.topk(gate_logits, self.args.num_experts_per_tok)\n",
    "            weights = F.softmax(weights, dim=1, dtype=torch.float).to(inputs.dtype)\n",
    "        \n",
    "        results = torch.zeros_like(inputs)\n",
    "        expert_tracking = {i: [] for i in range(self.args.num_experts)}\n",
    "        if expert_assignments is not None:\n",
    "            for current_expert_index, current_expert in enumerate(self.experts):\n",
    "                token_index = torch.where(selected_experts == current_expert_index)[0]  # Get the indices of tokens assigned to the current expert\n",
    "                for idx in token_index.cpu().numpy():\n",
    "                    expert_tracking[current_expert_index].append(idx)\n",
    "\n",
    "                # Correcting the shape by removing unsqueeze(1) and directly multiplying\n",
    "                results[token_index] += weights[token_index].unsqueeze(-1) * current_expert(inputs[token_index])\n",
    "\n",
    "        else:\n",
    "            for current_expert_index, current_expert in enumerate(self.experts):\n",
    "                token_index, token_expert_index = torch.where(selected_experts == current_expert_index)\n",
    "                for idx in token_index.cpu().numpy():\n",
    "                    expert_tracking[current_expert_index].append(idx)\n",
    "                results[token_index] += weights[token_index, token_expert_index, None] * current_expert(\n",
    "                    inputs[token_index]\n",
    "                )\n",
    "        \n",
    "        return results, loss_z, loss_b, expert_tracking\n",
    "\n",
    "\n",
    "\n",
    "class ModelArgs:\n",
    "    def __init__(self, dim: int, hidden_dim: int, num_labels: int, moe: MoeArgs):\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_labels = num_labels\n",
    "        self.moe = moe\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.w1 = nn.Linear(args.dim, args.hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(args.hidden_dim, args.dim, bias=False)\n",
    "        self.w3 = nn.Linear(args.dim, args.hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        return self.w2(nn.functional.silu(self.w1(x)) * self.w3(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab1cbaa-d9d7-4f12-a5f6-facfeed3ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomModel(nn.Module):\n",
    "#     def __init__(self,checkpoint,args: ModelArgs):\n",
    "#         super(CustomModel,self).__init__()\n",
    "\n",
    "#         self.model = model = AutoModel.from_pretrained(checkpoint,config=AutoConfig.from_pretrained(checkpoint, output_attentions=True,output_hidden_states=True))\n",
    "#         for param in self.model.parameters():\n",
    "#             param.requires_grad = False\n",
    "#         self.args=args\n",
    "#         self.moe_layer=MoeLayer(experts=[FeedForward(args=args) for _ in range(args.moe.num_experts)],gate=nn.Linear(args.dim, args.moe.num_experts, bias=False),moe_args=args.moe,)\n",
    "#         self.classifier = nn.Linear(768,args.num_labels)\n",
    "\n",
    "#     def forward(self, input_ids=None, attention_mask=None,labels=None):\n",
    "#         outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         moe_outputs,loss_z,loss_b,expert_tracking = self.moe_layer(outputs[0][:,0,:].view(-1,768))\n",
    "#         #expert_assignments = self.moe_layer.expert_assignments\n",
    "#         #print(experts)\n",
    "#         logits=self.classifier(moe_outputs)\n",
    "\n",
    "#         loss = None\n",
    "#         if labels is not None:\n",
    "#             loss_fct = nn.CrossEntropyLoss()\n",
    "#             loss = loss_fct(logits.view(-1, self.args.num_labels), labels.view(-1))\n",
    "#             loss=loss+loss_b+loss_z\n",
    "\n",
    "#         return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states,attentions=outputs.attentions),expert_tracking\n",
    "\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, checkpoint, args: ModelArgs):\n",
    "        super(CustomModel, self).__init__()\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(checkpoint, config=AutoConfig.from_pretrained(checkpoint, output_attentions=True, output_hidden_states=True))\n",
    "        self.args = args\n",
    "        self.moe_layer = MoeLayer(experts=[FeedForward(args=args) for _ in range(args.moe.num_experts)],\n",
    "                                  gate=nn.Linear(args.dim, args.moe.num_experts, bias=False),\n",
    "                                  moe_args=args.moe)\n",
    "        self.classifier = nn.Linear(768, args.num_labels)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, difficulty=None):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Map difficulty levels to expert indices\n",
    "        if difficulty is not None:\n",
    "            # Map difficulties: easy -> 0, ambiguous -> 1, hard -> 2\n",
    "            expert_assignments = difficulty\n",
    "        else:\n",
    "            expert_assignments = None\n",
    "\n",
    "        moe_outputs, loss_z, loss_b, expert_tracking = self.moe_layer(outputs[0][:, 0, :].view(-1, 768), expert_assignments=expert_assignments)\n",
    "        logits = self.classifier(moe_outputs)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.args.num_labels), labels.view(-1))\n",
    "            loss = loss + loss_b + loss_z\n",
    "\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions), expert_tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87075c03-8463-4410-ba04-d3f2d99d98c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pritam.k/research/envs/hf-envs/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 145883907\n"
     ]
    }
   ],
   "source": [
    "args=ModelArgs(dim=768,hidden_dim=3072,num_labels=3,moe=MoeArgs(num_experts,num_experts_per_tok))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=CustomModel(checkpoint=checkpoint,args=args).to(device)\n",
    "# model.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = DataParallel(model)\n",
    "model.to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e63be354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(\"../data/tweet_eval/updated/train.csv\")\n",
    "\n",
    "\n",
    "# df_train_easy = df_train[df_train['difficulty'] == 'easy']\n",
    "# df_train_ambi = df_train[df_train['difficulty'] == 'ambi']\n",
    "# df_train_hard = df_train[df_train['difficulty'] == 'hard']\n",
    "\n",
    "# easy_ids=df_train_easy.idx.values.tolist()\n",
    "# ambi_ids=df_train_ambi.idx.values.tolist()\n",
    "# hard_ids=df_train_hard.idx.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3016354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example tensor for difficulty levels\n",
    "# # Difficulty mapping: 0 for easy, 1 for ambiguous, 2 for hard\n",
    "# difficulty_levels = torch.tensor([0 if instance in easy_ids else 1 if instance in ambi_ids else 2 for instance in hard_ids], device=device)\n",
    "\n",
    "# # Pass the difficulty levels to the model during forward pass\n",
    "# output, expert_tracking = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask, labels=batch_labels, difficulty_levels=difficulty_levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8381938-7c8d-4b24-965f-5c732c6a52e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1785\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "num_epochs = num_epochs\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)\n",
    "\n",
    "metric = evaluate.combine([\n",
    "                evaluate.load('accuracy'), \n",
    "                ConfiguredMetric(evaluate.load('f1'), average='macro'),\n",
    "                ConfiguredMetric(evaluate.load('precision'), average='macro'),\n",
    "                ConfiguredMetric(evaluate.load('recall'), average='macro'),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ee641c9-e630-4538-9148-ec0ddbe4cf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1785 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [86, 768] doesn't match the broadcast shape [86, 86, 768]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_index\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m e}\n\u001b[0;32m---> 14\u001b[0m outputs, selected_experts \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     16\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Accumulate the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/research/envs/hf-envs/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/envs/hf-envs/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 50\u001b[0m, in \u001b[0;36mCustomModel.forward\u001b[0;34m(self, input_ids, attention_mask, labels, difficulty)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     expert_assignments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m moe_outputs, loss_z, loss_b, expert_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmoe_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpert_assignments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpert_assignments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(moe_outputs)\n\u001b[1;32m     53\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/research/envs/hf-envs/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/envs/hf-envs/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 64\u001b[0m, in \u001b[0;36mMoeLayer.forward\u001b[0;34m(self, inputs, expert_assignments)\u001b[0m\n\u001b[1;32m     61\u001b[0m             expert_tracking[current_expert_index]\u001b[38;5;241m.\u001b[39mappend(idx)\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;66;03m# Correcting the shape by removing unsqueeze(1) and directly multiplying\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m         results[token_index] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m weights[token_index]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m current_expert(inputs[token_index])\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m current_expert_index, current_expert \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperts):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [86, 768] doesn't match the broadcast shape [86, 86, 768]"
     ]
    }
   ],
   "source": [
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epochs * len(eval_dataloader)))\n",
    "\n",
    "train_losses = []  \n",
    "val_losses = []   \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    for batch in train_dataloader:\n",
    "        e = 'global_index'\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if k != e}\n",
    "        outputs, selected_experts = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()  # Accumulate the loss\n",
    "        num_batches += 1\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "    \n",
    "    avg_train_loss = total_loss / num_batches\n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch {epoch+1}, Training loss: {avg_train_loss}\")\n",
    "\n",
    "    # Evaluation step\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    num_val_batches = 0\n",
    "    for batch in eval_dataloader:\n",
    "        e = 'global_index'\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if k != e}\n",
    "        with torch.no_grad():\n",
    "            outputs, sel = model(**batch)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "        \n",
    "        # Calculate validation loss\n",
    "        val_loss = outputs.loss.item()  # Assuming outputs has a loss attribute\n",
    "        total_val_loss += val_loss\n",
    "        num_val_batches += 1\n",
    "        progress_bar_eval.update(1)\n",
    "\n",
    "    # Calculate the average validation loss for this epoch and store it\n",
    "    avg_val_loss = total_val_loss / num_val_batches\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(f\"Epoch {epoch+1}, Validation loss: {avg_val_loss}\")\n",
    "    print(metric.compute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19e2979d-0974-481b-8f64-75dcc63c27de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5346792575708238, 'f1': 0.3988003065228942, 'precision': 0.3878664292991636, 'recall': 0.45945052288798466}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pritam.k/research/envs/hf-envs/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metric_test = evaluate.combine([\n",
    "                evaluate.load('accuracy'), \n",
    "                ConfiguredMetric(evaluate.load('f1'), average='macro'),\n",
    "                ConfiguredMetric(evaluate.load('precision'), average='macro'),\n",
    "                ConfiguredMetric(evaluate.load('recall'), average='macro'),\n",
    "            ])\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"test\"], batch_size=batch_size, collate_fn=data_collator\n",
    ")\n",
    "expert_list=[]\n",
    "model.eval()\n",
    "for batch in test_dataloader:\n",
    "    key_to_exclude = 'global_index'\n",
    "    glo_batch = {k: v for k, v in batch.items() if k == key_to_exclude}\n",
    "    batch = {k: v.to(device) for k, v in batch.items() if k != key_to_exclude}\n",
    "    with torch.no_grad():\n",
    "        outputs, s = model(**batch)\n",
    "        for k in s.keys():\n",
    "            for i in range(len(s[k])):\n",
    "                index=s[k][i]\n",
    "                s[k][i]=glo_batch['global_index'][index].item()\n",
    "        expert_list.append(s)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    #print(f\"test: {s}\")\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric_test.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "\n",
    "# with open(\"results/expert_dist.pkl\", \"wb\") as pfile:\n",
    "#     pickle.dump(expert_list, pfile)\n",
    "results = metric_test.compute()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fad51a34-f5e3-46b9-8730-53ff840071ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [],\n",
       " 1: [],\n",
       " 2: [47615,\n",
       "  47616,\n",
       "  47617,\n",
       "  47618,\n",
       "  47619,\n",
       "  47620,\n",
       "  47621,\n",
       "  47622,\n",
       "  47623,\n",
       "  47624,\n",
       "  47625,\n",
       "  47626,\n",
       "  47627,\n",
       "  47628,\n",
       "  47629,\n",
       "  47630,\n",
       "  47631,\n",
       "  47632,\n",
       "  47633,\n",
       "  47634,\n",
       "  47635,\n",
       "  47636,\n",
       "  47637,\n",
       "  47638,\n",
       "  47639,\n",
       "  47640,\n",
       "  47641,\n",
       "  47642,\n",
       "  47643,\n",
       "  47644,\n",
       "  47645,\n",
       "  47646,\n",
       "  47647,\n",
       "  47648,\n",
       "  47649,\n",
       "  47650,\n",
       "  47651,\n",
       "  47652,\n",
       "  47653,\n",
       "  47654,\n",
       "  47655,\n",
       "  47656,\n",
       "  47657,\n",
       "  47658,\n",
       "  47659,\n",
       "  47660,\n",
       "  47661,\n",
       "  47662,\n",
       "  47663,\n",
       "  47664,\n",
       "  47665,\n",
       "  47666,\n",
       "  47667,\n",
       "  47668,\n",
       "  47669,\n",
       "  47670,\n",
       "  47671,\n",
       "  47672,\n",
       "  47673,\n",
       "  47674,\n",
       "  47675,\n",
       "  47676,\n",
       "  47677,\n",
       "  47678,\n",
       "  47679,\n",
       "  47680,\n",
       "  47681,\n",
       "  47682,\n",
       "  47683,\n",
       "  47684,\n",
       "  47685,\n",
       "  47686,\n",
       "  47687,\n",
       "  47688,\n",
       "  47689,\n",
       "  47690,\n",
       "  47691,\n",
       "  47692,\n",
       "  47693,\n",
       "  47694,\n",
       "  47695,\n",
       "  47696,\n",
       "  47697,\n",
       "  47698,\n",
       "  47699,\n",
       "  47700,\n",
       "  47701,\n",
       "  47702,\n",
       "  47703,\n",
       "  47704,\n",
       "  47705,\n",
       "  47706,\n",
       "  47707,\n",
       "  47708,\n",
       "  47709,\n",
       "  47710,\n",
       "  47711,\n",
       "  47712,\n",
       "  47713,\n",
       "  47714,\n",
       "  47715,\n",
       "  47716,\n",
       "  47717,\n",
       "  47718,\n",
       "  47719,\n",
       "  47720,\n",
       "  47721,\n",
       "  47722,\n",
       "  47723,\n",
       "  47724,\n",
       "  47725,\n",
       "  47726,\n",
       "  47727,\n",
       "  47728,\n",
       "  47729,\n",
       "  47730,\n",
       "  47731,\n",
       "  47732,\n",
       "  47733,\n",
       "  47734,\n",
       "  47735,\n",
       "  47736,\n",
       "  47737,\n",
       "  47738,\n",
       "  47739,\n",
       "  47740,\n",
       "  47741,\n",
       "  47742]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d3c58-6bfa-4f0b-90e8-5fdb8c7ad6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
